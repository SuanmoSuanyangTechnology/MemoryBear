# ============================================================================
# 基准测试统一配置文件示例
# ============================================================================
# 复制此文件为 .env.evaluation 并根据需要修改
# 支持的基准测试：LoCoMo、LongMemEval、MemSciQA
# ============================================================================

# ============================================================================
# 通用配置（所有基准测试共用）
# ============================================================================

# ----------------------------------------------------------------------------
# Neo4j 配置
# ----------------------------------------------------------------------------
# 默认 Group ID（建议各基准测试使用独立的 group）
EVAL_GROUP_ID=benchmark_default

# ----------------------------------------------------------------------------
# 模型配置（必需）
# ----------------------------------------------------------------------------
# ⚠️ 必填：从数据库 models 表中选择有效的模型 ID
# 
# 如何获取模型 ID：
# 1. 查询数据库：SELECT id, model_name FROM models WHERE is_active = true;
# 2. 或通过系统管理界面查看
# 3. 确保模型可用且配置正确

# LLM 模型 ID（必填）
EVAL_LLM_ID=your_llm_model_id_here

# Embedding 模型 ID（必填）
EVAL_EMBEDDING_ID=your_embedding_model_id_here

# ----------------------------------------------------------------------------
# 检索参数
# ----------------------------------------------------------------------------
# 检索类型: "keyword", "embedding", "hybrid"
EVAL_SEARCH_TYPE=hybrid

# 检索结果数量限制（默认值）
EVAL_SEARCH_LIMIT=12

# 上下文最大字符数（默认值）
EVAL_MAX_CONTEXT_CHARS=8000

# ----------------------------------------------------------------------------
# LLM 参数
# ----------------------------------------------------------------------------
# LLM 温度参数（0.0 = 确定性输出）
EVAL_LLM_TEMPERATURE=0.0

# LLM 最大生成 token 数
EVAL_LLM_MAX_TOKENS=32

# LLM 超时时间（秒）
EVAL_LLM_TIMEOUT=10.0

# LLM 最大重试次数
EVAL_LLM_MAX_RETRIES=1

# ----------------------------------------------------------------------------
# 数据处理参数
# ----------------------------------------------------------------------------
# Chunker 策略
EVAL_CHUNKER_STRATEGY=RecursiveChunker

# 是否在导入前清空现有数据
EVAL_RESET_ON_INGEST=true

# 是否保存详细日志
EVAL_SAVE_DETAILED_LOGS=true

# ============================================================================
# LoCoMo 基准测试专用配置
# ============================================================================
# 数据集：locomo10.json
# 运行：python locomo_benchmark.py --sample_size 20
# ----------------------------------------------------------------------------

# Group ID（LoCoMo 专用）
LOCOMO_GROUP_ID=locomo_benchmark

# 测试样本数量
# 建议值：20（快速测试）、100（中等测试）、1986（完整测试）
LOCOMO_SAMPLE_SIZE=20

# 检索结果数量限制
LOCOMO_SEARCH_LIMIT=12

# 上下文最大字符数
LOCOMO_CONTEXT_CHAR_BUDGET=8000

# 导入的对话数量
LOCOMO_MAX_DIALOGUES=1

# 结果保存目录
LOCOMO_OUTPUT_DIR=locomo/results

# ============================================================================
# LongMemEval 基准测试专用配置
# ============================================================================
# 数据集：longmemeval_oracle_zh.json
# 运行：python longmemeval_benchmark.py --sample_size 3
# 特点：支持时间推理问题的增强检索
# ----------------------------------------------------------------------------

# Group ID（LongMemEval 专用）
LONGMEMEVAL_GROUP_ID=longmemeval_zh_bak_3

# 测试样本数量（<=0 表示全部样本）
LONGMEMEVAL_SAMPLE_SIZE=3

# 起始样本索引
LONGMEMEVAL_START_INDEX=0

# 检索结果数量限制
LONGMEMEVAL_SEARCH_LIMIT=8

# 上下文最大字符数
LONGMEMEVAL_CONTEXT_CHAR_BUDGET=4000

# LLM 最大生成 token 数
LONGMEMEVAL_LLM_MAX_TOKENS=16

# 每条样本最多摄入的上下文段数
LONGMEMEVAL_MAX_CONTEXTS_PER_ITEM=2

# 是否保存分块结果
LONGMEMEVAL_SAVE_CHUNK_OUTPUT=true

# 自定义分块输出路径（留空使用默认）
LONGMEMEVAL_SAVE_CHUNK_OUTPUT_PATH=

# 摄入前是否清空组数据
LONGMEMEVAL_RESET_GROUP_BEFORE_INGEST=false

# 是否跳过摄入，仅检索评估
LONGMEMEVAL_SKIP_INGEST=false

# 结果保存目录
LONGMEMEVAL_OUTPUT_DIR=longmemeval/results

# ============================================================================
# MemSciQA 基准测试专用配置
# ============================================================================
# 数据集：msc_self_instruct.jsonl
# 运行：python memsciqa_benchmark.py --sample_size 1
# 特点：对话记忆检索评估
# ----------------------------------------------------------------------------

# Group ID（MemSciQA 专用，独立数据集）
MEMSCIQA_GROUP_ID=memsciqa_benchmark

# 测试样本数量
MEMSCIQA_SAMPLE_SIZE=1

# 检索结果数量限制
MEMSCIQA_SEARCH_LIMIT=8

# 上下文最大字符数
MEMSCIQA_CONTEXT_CHAR_BUDGET=4000

# LLM 最大生成 token 数
MEMSCIQA_LLM_MAX_TOKENS=64

# 结果保存目录
MEMSCIQA_OUTPUT_DIR=memsciqa/results

# ============================================================================
# 高级配置（可选）
# ============================================================================

# BM25 权重（用于混合检索，0.0-1.0）
EVAL_RERANK_ALPHA=0.6

# 是否使用遗忘重排序
EVAL_USE_FORGETTING_RERANK=false

# 是否使用 LLM 重排序
EVAL_USE_LLM_RERANK=false

# 连接重置间隔（每 N 个问题重置一次）
EVAL_RESET_INTERVAL=5

# 性能阈值（低于此值触发重置）
EVAL_PERFORMANCE_THRESHOLD=0.6

# ============================================================================
# 快速配置指南
# ============================================================================
# 1. 复制此文件为 .env.evaluation
# 2. 修改 EVAL_LLM_ID 和 EVAL_EMBEDDING_ID 为你的模型 ID
# 3. 根据需要修改各基准测试的专用配置
# 4. 运行测试：
#    - LoCoMo:       python locomo/locomo_benchmark.py --sample_size 20
#    - LongMemEval:  python longmemeval/longmemeval_benchmark.py --sample_size 3 --all
#    - MemSciQA:     python memsciqa/memsciqa_benchmark.py --sample_size 10
# 配置优先级：
#   命令行参数 > 特定配置（如 LOCOMO_*）> 通用配置（EVAL_*）> 代码默认值
# ============================================================================


# 执行LoCoMo测试
# 只摄入前5条消息，评估3个问题（最小测试）
# python -m app.core.memory.evaluation.locomo.locomo_benchmark --sample_size 3 --max_ingest_messages 5
#  
# 如果数据已经摄入，跳过摄入阶段直接测试
# python -m app.core.memory.evaluation.locomo.locomo_benchmark --sample_size 5 --skip_ingest


# 执行longmemeval测试
# python -m app.core.memory.evaluation.longmemeval.longmemeval_benchmark --sample-size 10 --max-contexts-per-item 3 --reset-group-before-ingest

# 执行memsciqa测试
# python -m app.core.memory.evaluation.memsciqa.memsciqa_benchmark --sample-size 1
